{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lmql\n",
    "from pprint import pprint\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5th of June.\n"
     ]
    }
   ],
   "source": [
    "@lmql.query\n",
    "def chain_of_thought(question):\n",
    "    '''lmql\n",
    "    # Q&A prompt template\n",
    "    \"Q: {question}\\n\"\n",
    "    \"A: Let's think step by step.\\n\"\n",
    "    \"[REASONING]\"\n",
    "    \"Thus, the answer is:[ANSWER].\"\n",
    "\n",
    "    # return just the ANSWER to the caller\n",
    "    return ANSWER\n",
    "    '''\n",
    "\n",
    "print(chain_of_thought('Today is the 12th of June, what day was it 1 week ago?'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\predator\\anaconda3\\envs\\gen-ai-and-llm-integration\\lib\\site-packages\\lmql\\runtime\\bopenai\\batched_openai.py:752: OpenAILogitBiasLimitationWarning: the required logit_bias is too large to be handled by the OpenAI API and will be limited to the first 300 tokens. This can lead to the violation of the provided constraints or undesired model output. To avoid this use less broad or no constraints.\n",
      "  warnings.warn(\"the required logit_bias is too large to be handled by the OpenAI API and will be limited to the first 300 tokens. This can lead to the violation of the provided constraints or undesired model output. To avoid this use less broad or no constraints.\", category=OpenAILogitBiasLimitationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LMQLResult(prompt='Review: We had a great stay. Hiking in the mountains \\n'\n",
      "                  '                    was fabulous and the food is really '\n",
      "                  'good.\\n'\n",
      "                  'Q: What is the underlying sentiment of this review and '\n",
      "                  'why?\\n'\n",
      "                  'A: The underlying sentiment of this review is positive '\n",
      "                  'because the reviewer had a great stay, enjoyed hiking in '\n",
      "                  'the mountains, and found the food to be really good.Based '\n",
      "                  'on this, the overall sentiment of the message can be '\n",
      "                  'considered to be positiveWhat is it that they liked about '\n",
      "                  'their stay? \\n'\n",
      "                  'The reviewer liked the hiking in the mountains and the '\n",
      "                  'food.',\n",
      "           variables={'ANALYSIS': ' The underlying sentiment of this review is '\n",
      "                                  'positive because the reviewer had a great '\n",
      "                                  'stay, enjoyed hiking in the mountains, and '\n",
      "                                  'found the food to be really good.',\n",
      "                      'CLS': ' positive',\n",
      "                      'FURTHER_ANALYSIS': '\\n'\n",
      "                                          'The reviewer liked the hiking in '\n",
      "                                          'the mountains and the food.'},\n",
      "           distribution_variable=None,\n",
      "           distribution_values=None)\n"
     ]
    }
   ],
   "source": [
    "@lmql.query\n",
    "def chain_of_thought(review):\n",
    "    '''lmql\n",
    "    argmax\n",
    "        \n",
    "        \"\"\"Review: {review}\n",
    "        Q: What is the underlying sentiment of this review and why?\n",
    "        A:[ANALYSIS]\"\"\" where not \"\\n\" in ANALYSIS\n",
    "        \n",
    "        \"Based on this, the overall sentiment of the message can be considered to be[CLS]\" where CLS in [\" positive\", \" neutral\", \" negative\"]\n",
    "        \n",
    "        if CLS == \" positive\":\n",
    "            \"What is it that they liked about their stay? [FURTHER_ANALYSIS]\"\n",
    "        elif CLS == \" neutral\":\n",
    "            \"What is it that could have been improved? [FURTHER_ANALYSIS]\"\n",
    "        elif CLS == \" negative\":\n",
    "            \"What is it that they did not like about their stay? [FURTHER_ANALYSIS]\"\n",
    "    where\n",
    "    STOPS_AT(FURTHER_ANALYSIS, \".\")\n",
    "    '''\n",
    "\n",
    "review = \"\"\"We had a great stay. Hiking in the mountains \n",
    "                    was fabulous and the food is really good.\"\"\"\n",
    "\n",
    "pprint(chain_of_thought(review))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gen-ai-and-llm-integration",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
